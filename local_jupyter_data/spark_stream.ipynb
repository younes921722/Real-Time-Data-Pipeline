{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd04e60e-bb43-4b3a-a62a-e692f8d9744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8eee713-ee9f-4abf-965e-a7b5eec82755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' istall the driver if does not exist '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" istall the driver if does not exist \"\"\"\n",
    "# !pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070f7790-64e4-4dfd-bd90-376a5be4efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace 'spark_streams' created (if not exists).\n",
      "Table 'created_users' created (if not exists).\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create the keyspace and created_users table for data loading if it does not exist \"\"\"\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['cassandra_db'])  # Update with your Cassandra host\n",
    "session = cluster.connect()\n",
    "\n",
    "# Create the keyspace\n",
    "keyspace_query = \"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS spark_streams \n",
    "WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\n",
    "\"\"\"\n",
    "session.execute(keyspace_query)\n",
    "print(\"Keyspace 'spark_streams' created (if not exists).\")\n",
    "\n",
    "# Use the keyspace\n",
    "session.set_keyspace('spark_streams')\n",
    "\n",
    "# Create the table\n",
    "table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS created_users (\n",
    "    first_name text,\n",
    "    last_name text,\n",
    "    gender text,\n",
    "    address text,\n",
    "    postcode text,\n",
    "    email text,\n",
    "    username text,\n",
    "    dob text,\n",
    "    registered text,\n",
    "    phone text,\n",
    "    picture text,\n",
    "    PRIMARY KEY ((first_name, last_name), email)\n",
    ");\n",
    "\"\"\"\n",
    "session.execute(table_query)\n",
    "print(\"Table 'created_users' created (if not exists).\")\n",
    "\n",
    "# Close the connection\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f692217-48c9-4b4e-bf1b-6f64ba682f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # .config('spark.jars', '/home/jovyan/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.3.0.jar')\n",
    "    # .config('spark.jars', '/home/jovyan/.ivy2/jars/postgresql-42.2.20.jar')\n",
    "    #.config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4711d4-2c17-42c9-a96d-f77cfd3323cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://5637b1523d86:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Writing to Multiple Sinks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f461c12b7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession \n",
    "#     .builder \n",
    "#     .appName(\"Streaming from Kafka\") \n",
    "#     .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "#     .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0')\n",
    "#     .config(\"spark.jars.packages\", 'com.datastax.spark:spark-cassandra-connector_2.12:3.3.0')\n",
    "#     .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "#     .master(\"local[*]\") \n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# spark\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession \n",
    "#     .builder \n",
    "#     .appName(\"Writing to Multiple Sinks\") \n",
    "#     .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "#     .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\")\n",
    "#     .config('spark.jars', '/home/jovyan/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.3.0.jar,/home/jovyan/.ivy2/jars/postgresql-42.2.20.jar')\n",
    "#     .config(\"spark.cassandra.connection.host\", \"cassandra_db\")  # Docker hostname\n",
    "#     .config(\"spark.cassandra.connection.port\", \"9042\")       # Default port\n",
    "#     .config(\"spark.cassandra.auth.username\", \"cassandra\")    # Credentials from your Docker setup\n",
    "#     .config(\"spark.cassandra.auth.password\", \"cassandra\")\n",
    "#     .config(\"spark.sql.shuffle.partitions\", 8)\n",
    "#     .master(\"local[*]\") \n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Writing to Multiple Sinks\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,com.datastax.spark:spark-cassandra-connector_2.12:3.3.0,org.postgresql:postgresql:42.2.20\")\n",
    "    .config(\"spark.cassandra.connection.host\", \"cassandra_db\")  # Docker hostname\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\")       # Default port\n",
    "    .config(\"spark.cassandra.auth.username\", \"cassandra\")    # Credentials from your Docker setup\n",
    "    .config(\"spark.cassandra.auth.password\", \"cassandra\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 8)\n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc0d75c-1bcb-4005-8060-3b88e4e0d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kafka_df to read from kafka\n",
    "\n",
    "kafka_df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"ed-kafka:29092\")\n",
    "    .option(\"subscribe\", \"users_created\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f20d80-0ab6-4bd8-997d-595f97f54175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View schema for raw kafka_df\n",
    "kafka_df.printSchema()\n",
    "#kafka_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70207504-3ccf-48e3-900c-eef8475d4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse value from binay to string into kafka_json_df\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a11a01f-56e3-4ba7-954b-55aa7a742c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, LongType\n",
    "\n",
    "json_schema = StructType([\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"address\", StringType(), True),\n",
    "        StructField(\"postcode\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"dob\", StringType(), True),\n",
    "        StructField(\"registered\", StringType(), True),\n",
    "        StructField(\"phone\", StringType(), True),\n",
    "        StructField(\"picture\", StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b5a63b-841b-4a98-a850-6c45d9aa2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the schema to payload to read the data\n",
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), json_schema)).selectExpr(\"values_json.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9648ad90-24bd-4204-a37a-389da52c6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- dob: timestamp (nullable = true)\n",
      " |-- registered: timestamp (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- picture: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To the schema of the data, place a sample json file and change readStream to read \n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Convert the 'dob' column to a timestamp\n",
    "streaming_df = streaming_df.withColumn(\"dob\", to_timestamp(\"dob\"))\n",
    "# Cast the 'registered' column to timestamp\n",
    "streaming_df = streaming_df.withColumn(\"registered\", to_timestamp(\"registered\"))\n",
    "\n",
    "streaming_df.printSchema()\n",
    "#streaming_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a03472-a8bf-477f-8ba1-7649fb44e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function to write to multiple sinks\n",
    "def device_data_output(df, batch_id):\n",
    "    print(\"Batch id: \"+ str(batch_id))\n",
    "    \n",
    "    # Write to parquet\n",
    "    df.write.format(\"parquet\").mode(\"append\").save(\"data/output/device_data.parquet/\")\n",
    "    \n",
    "    \n",
    "    # Write to JDBC Postgres\n",
    "    (\n",
    "        df.write\n",
    "        .mode(\"append\")\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres:5432/airflow\")\n",
    "        .option(\"dbtable\", \"loaded_users_data\")\n",
    "        .option(\"user\", \"airflow\")\n",
    "        .option(\"password\", \"airflow\")\n",
    "        .save()\n",
    "    \n",
    "    )\n",
    "   \n",
    "    # Write to Cassandra\n",
    "    (\n",
    "        df.write\n",
    "        .format(\"org.apache.spark.sql.cassandra\")\n",
    "        .mode(\"append\")\n",
    "        .option(\"table\", \"created_users\")\n",
    "        .option(\"keyspace\", \"spark_streams\")\n",
    "        .option(\"spark.cassandra.connection.host\", \"cassandra_db\")\n",
    "        .option(\"spark.cassandra.connection.port\", \"9042\")\n",
    "        .save()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Diplay\n",
    "    df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c886a7-ba5f-4289-b177-e7c31a33620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 0\n",
      "+----------+-----------+------+--------------------+--------+--------------------+------------------+--------------------+--------------------+--------------+--------------------+\n",
      "|first_name|  last_name|gender|             address|postcode|               email|          username|                 dob|          registered|         phone|             picture|\n",
      "+----------+-----------+------+--------------------+--------+--------------------+------------------+--------------------+--------------------+--------------+--------------------+\n",
      "|    Connor|      Meyer|  male|3476 York Road, K...|   20159|connor.meyer@exam...|      purplecat254|1969-11-28 07:57:...|2006-07-19 06:10:...|  021-198-8350|https://randomuse...|\n",
      "|  Danielle|       Beck|female|5946 Park Lane, W...|   53098|danielle.beck@exa...|   goldenrabbit747|1967-10-23 00:57:...|2004-10-14 10:54:...|  041-455-6813|https://randomuse...|\n",
      "|  Prvoslav|  Todorović|  male|7006 Belopoljska,...|   26941|prvoslav.todorovi...| beautifulzebra923|1966-04-10 21:36:...|2015-06-26 20:52:...|  039-0064-593|https://randomuse...|\n",
      "| Alexander|  Jørgensen|  male|1206 Fasanvej, Aa...|   70392|alexander.jorgens...|     whitesnake499|1981-10-29 15:33:...|2015-04-27 00:50:...|      38817050|https://randomuse...|\n",
      "|  Grimaldo|       Lugo|  male|4526 Viaducto Que...|   23762|grimaldo.lugo@exa...|  ticklishkoala805|1977-05-05 05:54:...|2019-03-04 10:41:...|(605) 030 5817|https://randomuse...|\n",
      "|      Aatu|      Manni|  male|8818 Otavalankatu...|   36438|aatu.manni@exampl...|      brownlion377|1956-05-02 22:53:...|2015-02-26 17:13:...|    05-718-141|https://randomuse...|\n",
      "|   Darrell|       Wood|  male|9311 Church Road,...|   67912|darrell.wood@exam...|     smallkoala778|1988-09-23 11:25:...|2015-07-24 14:35:...|  071-938-3621|https://randomuse...|\n",
      "|   Cameron|     Martin|  male|2618 The Crescent...| QJ3 0BH|cameron.martin@ex...|   whiteladybug869|1992-09-17 20:40:...|2007-10-21 07:49:...|   01395 04297|https://randomuse...|\n",
      "|   Jocélia|   da Costa|female|2875 Rua Bela Vis...|   26978|jocelia.dacosta@e...|       blackdog269|2001-05-14 20:05:...|2015-07-24 19:12:...|(60) 9036-1359|https://randomuse...|\n",
      "|     David|    Johnson|  male|9197 Clark Avenue...|   15366|david.johnson@exa...|  orangemeercat545|1988-06-04 10:15:...|2003-10-11 07:27:...|(973)-051-4638|https://randomuse...|\n",
      "|  Jonathan|     Prieto|  male|7389 Calle de Áng...|   32502|jonathan.prieto@e...|      bluesnake188|1968-04-12 22:48:...|2007-05-10 00:03:...|   944-832-818|https://randomuse...|\n",
      "|    Samuel|      Green|  male|7575 South Wester...|   45627|samuel.green@exam...| purpleelephant930|1956-09-01 04:27:...|2003-03-20 18:04:...|(103)-946-1382|https://randomuse...|\n",
      "|  Remedios|    Vázquez|female|2211 Calle de Art...|   73111|remedios.vazquez@...|     smallkoala254|1968-10-11 08:15:...|2002-08-23 13:32:...|   918-536-875|https://randomuse...|\n",
      "| Zvenislav|    Orlenko|  male|4486 Lukasha, Vas...|   68706|zvenislav.orlenko...|    blackrabbit152|1992-07-24 22:46:...|2014-02-28 21:14:...|(067) X85-2793|https://randomuse...|\n",
      "|      Aria|    Jackson|female|4002 Bay View Roa...|   21662|aria.jackson@exam...|    bluepeacock752|1947-01-31 07:16:...|2007-10-25 19:34:...|(533)-053-1712|https://randomuse...|\n",
      "|  Brittany|       Diaz|female|7250 W Belt Line ...|   52837|brittany.diaz@exa...| beautifulsnake608|1969-01-12 08:54:...|2002-05-29 18:54:...|(531) 387-0454|https://randomuse...|\n",
      "|     Aaron|    Schmitt|  male|3232 Rue Courbet,...|   44214|aaron.schmitt@exa...|     blackpanda644|1949-11-27 07:26:...|2015-07-22 10:51:...|04-52-95-91-38|https://randomuse...|\n",
      "| Afanasiya|Zagorodnyuk|female|8226 Yasinuvatska...|   92034|afanasiya.zagorod...|    goldenpanda912|1951-03-31 04:16:...|2014-08-05 16:40:...|(068) D93-9744|https://randomuse...|\n",
      "|      Rosa|     Madsen|female|1211 Søndertoften...|   55302|rosa.madsen@examp...|    lazyladybug833|1993-06-30 07:28:...|2002-07-16 00:20:...|      19157547|https://randomuse...|\n",
      "|      Axel|   Lefebvre|  male|4986 Avenue Jolio...|   97399|axel.lefebvre@exa...|beautifulrabbit407|1960-03-10 15:56:...|2008-06-05 14:25:...|03-24-56-37-63|https://randomuse...|\n",
      "+----------+-----------+------+--------------------+--------+--------------------+------------------+--------------------+--------------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running foreachBatch\n",
    "# Write the output to Multiple Sinks\n",
    "(streaming_df\n",
    " .writeStream\n",
    " .foreachBatch(device_data_output)\n",
    " .trigger(processingTime='10 seconds')\n",
    " .option(\"checkpointLocation\", \"checkpoint_dir_kafka\")\n",
    " .start()\n",
    " .awaitTermination())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc59bf-314e-4fda-b5a2-634111eefb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
