{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04e60e-bb43-4b3a-a62a-e692f8d9744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8eee713-ee9f-4abf-965e-a7b5eec82755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' istall the driver if does not exist '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" istall the driver if does not exist \"\"\"\n",
    "# !pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070f7790-64e4-4dfd-bd90-376a5be4efcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Create the keyspace and created_users table for data loading if it does not exist '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Create the keyspace and created_users table for data loading if it does not exist \"\"\"\n",
    "\n",
    "# from cassandra.cluster import Cluster\n",
    "\n",
    "# cluster = Cluster(['cassandra'])  # Update with your Cassandra host\n",
    "# session = cluster.connect()\n",
    "\n",
    "# # Create the keyspace\n",
    "# keyspace_query = \"\"\"\n",
    "# CREATE KEYSPACE IF NOT EXISTS spark_streams \n",
    "# WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\n",
    "# \"\"\"\n",
    "# session.execute(keyspace_query)\n",
    "# print(\"Keyspace 'spark_streams' created (if not exists).\")\n",
    "\n",
    "# # Use the keyspace\n",
    "# session.set_keyspace('spark_streams')\n",
    "\n",
    "# # Create the table\n",
    "# table_query = \"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS created_users (\n",
    "#     first_name text,\n",
    "#     last_name text,\n",
    "#     gender text,\n",
    "#     address text,\n",
    "#     postcode text,\n",
    "#     email text,\n",
    "#     username text,\n",
    "#     dob text,\n",
    "#     registered text,\n",
    "#     phone text,\n",
    "#     picture text,\n",
    "#     PRIMARY KEY ((first_name, last_name), email)\n",
    "# );\n",
    "# \"\"\"\n",
    "# session.execute(table_query)\n",
    "# print(\"Table 'created_users' created (if not exists).\")\n",
    "\n",
    "# # Close the connection\n",
    "# cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4711d4-2c17-42c9-a96d-f77cfd3323cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cda2dc3da6c3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Writing to Multiple Sinks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7e4bb1ada0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession \n",
    "#     .builder \n",
    "#     .appName(\"Streaming from Kafka\") \n",
    "#     .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "#     .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0')\n",
    "#     .config(\"spark.jars.packages\", 'com.datastax.spark:spark-cassandra-connector_2.12:3.3.0')\n",
    "#     .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "#     .master(\"local[*]\") \n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Writing to Multiple Sinks\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0')\n",
    "    .config('spark.jars', '/home/jovyan/.ivy2/jars/postgresql-42.2.20.jar')\n",
    "    .config(\"spark.sql.shuffle.partitions\", 8)\n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc0d75c-1bcb-4005-8060-3b88e4e0d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kafka_df to read from kafka\n",
    "\n",
    "kafka_df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"ed-kafka:29092\")\n",
    "    .option(\"subscribe\", \"users_created\")\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f20d80-0ab6-4bd8-997d-595f97f54175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View schema for raw kafka_df\n",
    "kafka_df.printSchema()\n",
    "#kafka_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70207504-3ccf-48e3-900c-eef8475d4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse value from binay to string into kafka_json_df\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a11a01f-56e3-4ba7-954b-55aa7a742c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, LongType\n",
    "\n",
    "json_schema = StructType([\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"address\", StringType(), True),\n",
    "        StructField(\"postcode\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"dob\", StringType(), True),\n",
    "        StructField(\"registered\", StringType(), True),\n",
    "        StructField(\"phone\", StringType(), True),\n",
    "        StructField(\"picture\", StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b5a63b-841b-4a98-a850-6c45d9aa2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the schema to payload to read the data\n",
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), json_schema)).selectExpr(\"values_json.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9648ad90-24bd-4204-a37a-389da52c6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- dob: timestamp (nullable = true)\n",
      " |-- registered: timestamp (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- picture: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To the schema of the data, place a sample json file and change readStream to read \n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Convert the 'dob' column to a timestamp\n",
    "streaming_df = streaming_df.withColumn(\"dob\", to_timestamp(\"dob\"))\n",
    "# Cast the 'registered' column to timestamp\n",
    "streaming_df = streaming_df.withColumn(\"registered\", to_timestamp(\"registered\"))\n",
    "\n",
    "streaming_df.printSchema()\n",
    "#streaming_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a03472-a8bf-477f-8ba1-7649fb44e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function to write to multiple sinks\n",
    "def device_data_output(df, batch_id):\n",
    "    print(\"Batch id: \"+ str(batch_id))\n",
    "    \n",
    "    # Write to parquet\n",
    "    df.write.format(\"parquet\").mode(\"append\").save(\"data/output/device_data.parquet/\")\n",
    "    \n",
    "    \n",
    "    # Write to JDBC Postgres\n",
    "    (\n",
    "        df.write\n",
    "        .mode(\"append\")\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres:5432/airflow\")\n",
    "        .option(\"dbtable\", \"loaded_users_data\")\n",
    "        .option(\"user\", \"airflow\")\n",
    "        .option(\"password\", \"airflow\")\n",
    "        .save()\n",
    "    \n",
    "    )\n",
    "    \n",
    "    # Diplay\n",
    "    df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c886a7-ba5f-4289-b177-e7c31a33620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 27\n",
      "+----------+---------+------+--------------------+--------+--------------------+----------------+--------------------+--------------------+--------------+--------------------+\n",
      "|first_name|last_name|gender|             address|postcode|               email|        username|                 dob|          registered|         phone|             picture|\n",
      "+----------+---------+------+--------------------+--------+--------------------+----------------+--------------------+--------------------+--------------+--------------------+\n",
      "|     Conor| Salomons|  male|6926 Delftsestraa...| 8671 BL|conor.salomons@ex...|ticklishpanda519|1984-07-17 21:34:...|2017-03-24 07:53:...| (008) 8331289|https://randomuse...|\n",
      "|      Wade|    Young|  male|3002 Westheimer R...|   34625|wade.young@exampl...|     crazycat493|1991-10-06 15:24:...|2020-12-19 01:38:...|(511) 233-4247|https://randomuse...|\n",
      "|  محمدطاها|     گلشن|  male|6724 برادران سلیم...|   42277|mhmdth.glshn@exam...|     lazyfish870|1959-04-05 18:18:...|2016-01-04 15:41:...|  091-15864043|https://randomuse...|\n",
      "+----------+---------+------+--------------------+--------+--------------------+----------------+--------------------+--------------------+--------------+--------------------+\n",
      "\n",
      "Batch id: 28\n",
      "+----------+-----------+------+--------------------+--------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+\n",
      "|first_name|  last_name|gender|             address|postcode|               email|         username|                 dob|          registered|         phone|             picture|\n",
      "+----------+-----------+------+--------------------+--------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+\n",
      "|     Mikey|       Chen|  male|4322 Hendrik Munn...| 0938 UL|mikey.chen@exampl...|    smallkoala818|1983-07-18 23:35:...|2016-05-03 15:34:...| (0349) 814766|https://randomuse...|\n",
      "|   Mihaela|      Kralj|female|7151 Oslobođenja,...|   96389|mihaela.kralj@exa...|happybutterfly657|2000-06-10 19:11:...|2017-03-06 17:40:...|  020-2405-618|https://randomuse...|\n",
      "|      Eeli|   Saarinen|  male|6787 Suvantokatu,...|   99880|eeli.saarinen@exa...| purpleladybug147|1967-02-02 16:30:...|2014-02-10 15:26:...|    03-819-068|https://randomuse...|\n",
      "|     Chris|   Castillo|  male|3836 Stevens Cree...|   63204|chris.castillo@ex...|     greenfish281|1961-05-29 02:46:...|2012-09-04 21:25:...|(676) 250-1201|https://randomuse...|\n",
      "|    Torben|    Smistad|  male|6149 Utfartsveien...|    7250|torben.smistad@ex...|    redpeacock791|1994-05-05 08:46:...|2019-12-08 02:30:...|      36941096|https://randomuse...|\n",
      "|     Maria|Christensen|female|525 Byvangen, Ros...|   36050|maria.christensen...|     blackduck920|1974-11-24 20:24:...|2021-04-21 22:02:...|      82734939|https://randomuse...|\n",
      "|     Hilla|    Huotari|female|2393 Satakennanka...|   90217|hilla.huotari@exa...|     orangecat675|1950-07-11 02:33:...|2020-11-28 23:49:...|    03-331-530|https://randomuse...|\n",
      "|    Archer|   Anderson|  male|5056 Wilson Road,...|   61665|archer.anderson@e...| beautifulfrog131|1977-07-12 17:49:...|2005-09-07 05:21:...|(247)-642-3379|https://randomuse...|\n",
      "|    Hunter|       Wang|  male|3249 Victoria Roa...|   38273|hunter.wang@examp...|  redbutterfly313|1981-08-22 03:28:...|2014-12-06 05:36:...|(116)-589-5243|https://randomuse...|\n",
      "|       Ava|      Jones|female|7459 Pakowhai Roa...|   27556|ava.jones@example...|    redpeacock681|1970-09-23 20:35:...|2018-05-11 03:14:...|(348)-174-2560|https://randomuse...|\n",
      "| Anne-Lise|     Michel|female|2071 Montée Saint...|    6596|anne-lise.michel@...| brownelephant425|1998-04-25 07:34:...|2003-07-12 17:12:...| 076 839 44 20|https://randomuse...|\n",
      "|  Dingeman|   Klooster|  male|3050 Haamakkerswe...| 7361 KV|dingeman.klooster...|      lazybird197|1987-06-21 13:43:...|2019-01-19 08:32:...| (0609) 204507|https://randomuse...|\n",
      "|     Benta|    da Mata|female|7226 Rua Bela Vis...|   12975|benta.damata@exam...|     blackbird671|1945-06-30 08:21:...|2019-08-02 17:38:...|(53) 4643-4787|https://randomuse...|\n",
      "|    August|    Nielsen|  male|3736 Tolstrupvej,...|   56446|august.nielsen@ex...| yellowmeercat599|1957-04-09 15:14:...|2012-01-19 12:38:...|      24531356|https://randomuse...|\n",
      "|   Avreliy|    Yanchik|  male|1334 Oleksiya Ber...|   85103|avreliy.yanchik@e...|      lazyfish541|1985-04-30 16:53:...|2020-12-01 07:31:...|(068) H15-1727|https://randomuse...|\n",
      "|     Susan|   Crawford|female|3893 Victoria Roa...|   77902|susan.crawford@ex...|    blackmouse986|1986-11-07 08:06:...|2020-01-01 23:21:...|  051-146-3927|https://randomuse...|\n",
      "|    Branko|      Trapp|  male|9906 Kirchstraße,...|   84548|branko.trapp@exam...|     redrabbit867|1994-01-01 19:05:...|2014-03-12 04:12:...|  0142-9903426|https://randomuse...|\n",
      "|    Robert|     Harper|  male|1730 Jones Road, ...|   66464|robert.harper@exa...|     greenswan659|1945-08-28 04:16:...|2020-06-16 01:20:...|  061-385-8622|https://randomuse...|\n",
      "|   Kristin|    Aanstad|female|655 Thorvald Meye...|    4260|kristin.aanstad@e...|  brownladybug972|1996-09-08 13:52:...|2018-11-19 19:40:...|      37332210|https://randomuse...|\n",
      "|      كيان|   كامياران|  male|1793 شهید استاد ح...|   84872|kyn.kmyrn@example...|    sadgorilla704|1988-05-19 14:12:...|2005-10-10 18:50:...|  095-64925954|https://randomuse...|\n",
      "+----------+-----------+------+--------------------+--------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running foreachBatch\n",
    "# Write the output to Multiple Sinks\n",
    "(streaming_df\n",
    " .writeStream\n",
    " .foreachBatch(device_data_output)\n",
    " .trigger(processingTime='10 seconds')\n",
    " .option(\"checkpointLocation\", \"checkpoint_dir_kafka\")\n",
    " .start()\n",
    " .awaitTermination())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c789d5e-5efa-441d-93a0-33ff1f915414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173aa37d-3dbc-4789-8718-0c0de95074b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
